<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Lucene学习入门]]></title>
    <url>%2F2018%2F12%2F02%2FLucene%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[https://v1.hitokoto.cn/?c=f&amp;encode=text https://v1.hitokoto.cn/?c=f&amp;encode=text 一.搜索引擎原理. 二.什么是lucene1234Lucene是一套用于全文检索和搜寻的开源程序库，由Apache软件基金会支持和提供.Lucene提供了一个简单却强大的应用程序接口（API），能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放源代码工具.Lucene并不是现成的搜索引擎产品，但可以用来制作搜索引擎产品.官网：http://lucene.apache.org/ 1.什么是全文检索.如何实现.计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式.通过分词. 对要搜索的内容先创建索引,然后再通过索引进行搜索的过程. 倒排索引: 又叫反向索引,以字或词为关键字进行索引，表中关键字所对应的记录表项，记录了出现这个字或词的所有文档，每一个表项记录该文档的ID和关键字在该文档中出现的位置情况. 总结：对文档（数据）中每一个词都做索引. 2.索引和搜索的流程 12341、绿色表示索引过程，对要搜索的原始内容进行索引构建一个索引库，索引过程包括：确定原始内容即要搜索的内容--&gt;采集文档--&gt;创建文档对象--&gt;分析文档--&gt;索引文档.2、红色表示搜索过程，从索引库中搜索内容，搜索过程包括：用户通过搜索界面--&gt;创建查询--&gt;执行搜索，从索引库搜索--&gt;渲染搜索结果. 二.Lucene的基本使用使用Lucene的API来实现对索引的增（创建索引）、删（删除索引）、改（修改索引）、查（搜索数据） 1.新建一个普通的maven项目.2.导入pom相关依赖.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//(出现红叉记得maven/update project)&lt;dependencies&gt; &lt;!-- Junit单元测试 --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!-- lucene核心库 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;4.10.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Lucene的查询解析器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;4.10.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- lucene的默认分词器库 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt; &lt;version&gt;4.10.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- lucene的高亮显示 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-highlighter&lt;/artifactId&gt; &lt;version&gt;4.10.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- io流 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- java编译插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 3.创建索引库123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Lucene &#123; @Test public void createIndex() throws Exception &#123; // 创建目录对象，指定索引库的存放位置；FSDirectory文件系统；RAMDirectory内存 // 索引库保存到内存中,一般不用 // Directory directory=new RAMDirectory(); // 保存到磁盘 Directory directory = FSDirectory.open(new File("D:\\lucene\\index")); // 创建分词器对象 Analyzer analyzer = new StandardAnalyzer(); // 创建索引写入器配置对象，第一个参数版本VerSion.LATEST,第一个参数分词器 IndexWriterConfig conf = new IndexWriterConfig(Version.LATEST, analyzer); // 创建一个索引写入器(IndexWriter),参数1:索引库存放的路径,参数2:配置信息,其中包括分词器对象. IndexWriter indexWriter = new IndexWriter(directory, conf); // 获得原始文档,使用io流读取文本文件 File docPath=new File("D:\\lucene\\searchsource"); for (File f : docPath.listFiles()) &#123; //取文件名 String fileName = f.getName(); //取文件路径 String filePath = f.getPath(); //文件内容 String fileContent = FileUtils.readFileToString(f); //文件大小 long fileSize = FileUtils.sizeOf(f); // 创建文档对象 Document document = new Document(); //创建域 //参数1：域的名称 参数2：域的内容 参数3：是否存储 TextField fileNameField = new TextField("name", fileName, Store.YES); StoredField filePathField = new StoredField("path", filePath); TextField fileContentField = new TextField("content", fileContent, Store.NO); LongField fileSizeField = new LongField("size", fileSize, Store.YES); //5、向文档中添加域(term) document.add(fileNameField); document.add(filePathField); document.add(fileContentField); document.add(fileSizeField); //6、把文档对象写入索引库 indexWriter.addDocument(document); &#125; // 关闭IndexWriter对象 indexWriter.close(); &#125;&#125; 运行创建索引库成功: 4.使用luke工具查看索引文件运行start.bat打开. 文档列表: 搜索页面: 5.查询索引器1234567891011121314151617181920212223242526272829303132//查询索引库 @Test public void searchIndex() throws Exception &#123; //1指定索引库存放的位置 Directory directory = FSDirectory.open(new File("D:\\lucene\\index")); //2使用IndexReader对象打开索引库 IndexReader indexReader = DirectoryReader.open(directory); //3创建一个IndexSearcher对象，构造方法需要一个indexReader对象 IndexSearcher indexSearcher = new IndexSearcher(indexReader); //4创建一个查询对象,需要指定查询域及要查询的关键字。 //term的参数1：要搜索的域, 参数2：搜索的关键字 Query query = new TermQuery(new Term("name", "apache")); //参数1：查询条件, 参数2：查询结果返回的最大值 //5取查询结果 TopDocs topDocs = indexSearcher.search(query, 10); //取查询结果总记录数 System.out.println("查询结果总记录数：" + topDocs.totalHits); //6遍历查询结果并打印. for (ScoreDoc scoreDoc : topDocs.scoreDocs) &#123; //取文档id int id = scoreDoc.doc; //从索引库中取文档对象 Document document = indexSearcher.doc(id); //取属性 System.out.println(document.get("name")); System.out.println(document.get("size")); System.out.println(document.get("content")); System.out.println(document.get("path")); &#125; //7关闭IndexReader对象 indexReader.close(); &#125; 6.IK中文分词器优点: 中文分词更专业,可以扩展自定义词库(扩展词典和停用词典). 12345678910&lt;!-- 引入IK分词器 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.janeluo&lt;/groupId&gt; &lt;artifactId&gt;ikanalyzer&lt;/artifactId&gt; &lt;version&gt;2012_u6&lt;/version&gt; &lt;/dependency&gt;//将自定义词库的三个配置文件放到classpath下.//exit.dic 扩展词典//stopword.dic 停用词典//IKAnalyzer ik配置文件 12345678910111213141516171819202122232425262728293031//查看IK分析器的分词效果 @Test public void testAnanlyzer() throws Exception &#123; //创建一个分析器对象 //标准分词器 //Analyzer analyzer = new StandardAnalyzer(); //Analyzer analyzer = new CJKAnalyzer(); //智能中文分词器 //Analyzer analyzer = new SmartChineseAnalyzer(); //IK中文分词器 Analyzer analyzer = new IKAnalyzer(); //从分析器对象中获得tokenStream对象 //参数1：域的名称，可以为null或者"" //参数2：要分析的文本内容 TokenStream tokenStream = analyzer.tokenStream("", "设置一个引用，引用可以有多重类型，可以时候关键词的引用、偏移量的引用"); //设置一个引用，引用可以有多重类型，可以时候关键词的引用、偏移量的引用 CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class); //偏移量 OffsetAttribute offsetAttribute = tokenStream.addAttribute(OffsetAttribute.class); //调用tokenStream的reset方法 tokenStream.reset(); //使用while循环变量单词列表 while (tokenStream.incrementToken()) &#123; System.out.println("start-&gt;" + offsetAttribute.startOffset()); //打印单词 System.out.println(charTermAttribute); System.out.println("end-&gt;" + offsetAttribute.endOffset()); &#125; //关闭tokenStream tokenStream.close(); &#125; 7.添加文档1234567891011121314151617181920//添加文档 @Test public void addDocument() throws Exception &#123; Directory directory = FSDirectory.open(new File("D:\\lucene\\index")); Analyzer analyzer = new IKAnalyzer(); //参数1：lucene的版本号，第二个参数：分析器对象 IndexWriterConfig conf = new IndexWriterConfig(Version.LATEST, analyzer); IndexWriter indexWriter = new IndexWriter(directory, conf); //创建Document对象 Document document = new Document(); //创建域 TextField FileNameField = new TextField("name", "测试文件.txt", Store.YES); StoredField FilepathField = new StoredField("path", "D:\\lucene\\测试文件.txt"); document.add(FileNameField); document.add(FilepathField); //写入索引库 indexWriter.addDocument(document); //关闭资源 indexWriter.close(); &#125; 8.删除文档1234567891011121314151617181920212223242526272829public IndexWriter getIndexWriter() throws Exception &#123; Directory directory = FSDirectory.open(new File("D:\\lucene\\index")); Analyzer analyzer = new IKAnalyzer(); //参数1：lucene的版本号，第二个参数：分析器对象 IndexWriterConfig conf = new IndexWriterConfig(Version.LATEST, analyzer); IndexWriter indexWriter = new IndexWriter(directory, conf); return indexWriter; &#125;//删除全部文档(慎用!!!) @Test public void deleteAllDocument() throws Exception &#123; //获得IndexWriter对象 IndexWriter indexWriter = this.getIndexWriter(); //调用删除方法删除索引库 indexWriter.deleteAll(); //关闭资源 indexWriter.close(); &#125;//根据查询条件删除 @Test public void deleteDocumentByQuery() throws Exception &#123; IndexWriter indexWriter = this.getIndexWriter(); //指定查询条件 Query query = new TermQuery(new Term("name", "apache")); //删除文档 indexWriter.deleteDocuments(query); //关闭资源 indexWriter.close(); &#125; 9.更新索引库12345678910111213//更新索引库(本质:先删除后添加) @Test public void updateDocument() throws Exception &#123; IndexWriter indexWriter = this.getIndexWriter(); //创建一个新的文档对象 Document document = new Document(); document.add(new TextField("name", "更新后的文档", Store.YES)); document.add(new TextField("content", "更新后的文档内容", Store.YES)); //term对象：指定要删除域及要删除的关键词，先根据term查询，把查询结果删除，然后追加一个新的文档。 indexWriter.updateDocument(new Term("name", "spring"), document); //关闭资源 indexWriter.close(); &#125; 10.Query子类查询-查询所有文档1234567891011121314151617181920212223242526272829303132//查询所有文档public class SearchIndex &#123; @Test public void testMatchAllDocsQuery() throws Exception &#123; //指定索引库存放的路径 Directory directory = FSDirectory.open(new File("D:\\lucene\\index")); //创建一个IndexReader对象 IndexReader indexReader = DirectoryReader.open(directory); //创建IndexSearcher对象 IndexSearcher indexSearcher = new IndexSearcher(indexReader); //创建一个Query对象,匹配所有文档查询 Query query = new MatchAllDocsQuery(); System.out.println(query); //查询索引库 TopDocs topDocs = indexSearcher.search(query, 100); ScoreDoc[] scoreDocs = topDocs.scoreDocs; System.out.println("查询结果总记录数：" + topDocs.totalHits); //遍历查询结果 for (ScoreDoc scoreDoc : scoreDocs) &#123; int docId = scoreDoc.doc; //通过id查询文档对象 Document document = indexSearcher.doc(docId); //取属性 System.out.println(document.get("name")); System.out.println(document.get("size")); System.out.println(document.get("content")); System.out.println(document.get("path")); &#125; //关闭索引库 indexReader.close(); &#125;&#125; 1234567891011121314151617181920212223242526//提取重复代码private IndexSearcher getIndexSearcher() throws Exception &#123; //指定索引库存放的路径 Directory directory = FSDirectory.open(new File("D:\\lucene\\index")); //创建一个IndexReader对象 IndexReader indexReader = DirectoryReader.open(directory); //创建IndexSearcher对象 IndexSearcher indexSearcher = new IndexSearcher(indexReader); return indexSearcher; &#125; private void printResult(IndexSearcher indexSearcher, Query query) throws Exception &#123; //查询索引库 TopDocs topDocs = indexSearcher.search(query, 100); ScoreDoc[] scoreDocs = topDocs.scoreDocs; System.out.println("查询结果总记录数：" + topDocs.totalHits); //遍历查询结果 for (ScoreDoc scoreDoc : scoreDocs) &#123; int docId = scoreDoc.doc; //通过id查询文档对象 Document document = indexSearcher.doc(docId); //取属性 System.out.println(document.get("name")); System.out.println(document.get("size")); System.out.println(document.get("content")); System.out.println(document.get("path")); &#125; 11.数值范围查询123456789@Test public void testNumericRangeQuery() throws Exception &#123; //创建一个数值范围查询对象 //参数1：要查询的域 参数2：最小值 参数3：最大值 参数4：是否包含最小值 参数5：是否包含最大值 Query query = NumericRangeQuery.newLongRange("size", 1000l, 10000l, false, true); System.out.println(query); //打印结果 printResult(getIndexSearcher(), query); &#125; 12.组合条件查询1234567891011121314151617181920//Occur.MUST：必须满足此条件，相当于and//Occur.SHOULD：应该满足，但是不满足也可以，相当于or//Occur.MUST_NOT：必须不满足。相当于not//组合条件查询 @Test public void testBooleanQuery() throws Exception &#123; //创建一个BooleanQuery对象 BooleanQuery query = new BooleanQuery(); //创建子查询，文件大于1000小于10000 //Query query1 = NumericRangeQuery.newLongRange("size", 1000l, 10000l, true, true); Query query1 = new TermQuery(new Term("name", "lucene")); //文件名中包含mybatis关键字 Query query2 = new TermQuery(new Term("name", "apache")); //添加到BooleanQuery对象中 query.add(query1, Occur.MUST); query.add(query2, Occur.MUST_NOT); System.out.println(query); //执行查询 printResult(getIndexSearcher(), query); &#125; 13.使用Queryparse查询通过QueryParser也可以创建Query，QueryParser提供一个Parse方法，此方法可以直接根据查询语法来查询。Query对象执行的查询语法可通过System.out.println(query);查询。需要使用到分析器。建议创建索引时使用的分析器和查询索引时使用的分析器要一致。 1234567891011 @Test public void testQueryParser() throws Exception &#123; //创建一个QueryParser对象。参数1：默认搜索域 参数2：分析器对象。 QueryParser queryParser = new QueryParser("content", new IKAnalyzer()); //调用parse方法可以获得一个Query对象 //参数：要查询的内容，可以是一句话。先分词在查询 Query query = queryParser.parse("mybatis is a apache project");// Query query = queryParser.parse("name:lucene OR name:apache"); System.out.println(query); printResult(getIndexSearcher(), query); &#125; 14.Lucene查询语法123456789101112131415161718192021222324251、基础的查询语法，关键词查询：域名+“：”+搜索的关键字例如：content:java2、范围查询域名+“:”+[最小值 TO 最大值]例如：size:[1 TO 1000]范围查询在lucene中不支持数值类型，支持字符串类型。在solr中支持数值类型。3、组合条件查询1）+条件1 +条件2：两个条件之间是并且的关系and例如：+filename:apache +content:apache2）+条件1 条件2：必须满足第一个条件，应该满足第二个条件例如：+filename:apache content:apache3）条件1 条件2：两个条件满足其一即可。例如：filename:apache content:apache4）-条件1 条件2：必须不满足条件1，要满足条件2例如：-filename:apache content:apacheOccur.MUST 查询条件必须满足，相当于and +（加号）Occur.SHOULD 查询条件可选，相当于or 空（不用符号）Occur.MUST_NOT 查询条件不能满足，相当于not非 -（减号）第二种写法：条件1 AND 条件2条件1 OR 条件2条件1 NOT 条件2 15.指定多个默认搜索域123456789@Testpublic void testMultiFileQueryParser() throws Exception &#123; //指定默认搜索域 String[] fields =&#123;"name", "content"&#125;; MultiFieldQueryParser queryParser = new MultiFieldQueryParser(fields, new IKAnalyzer()); Query query = queryParser.parse("mybatis is a apache project"); System.out.println(query); printResult(getIndexSearcher(), query);&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客搭建]]></title>
    <url>%2F2018%2F12%2F02%2FHexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[第一篇博客，感谢阅读，多多指教。 什么是HexoHexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。本博客即使用hexo+github搭建而成，在此记录一下过程。 搭建环境： Win10x64位，hexo 3.8.0,Node 8.11.3,Git 2.18.0 安装Hexo前提先安装两个软件，点击官网安装Node.js和Git，默认安装即可。Git安装完成后鼠标右击桌面会出现两个选项图标，点击框中那个，这个以后会经常用到。 1.新建一个文件夹取名，比如我的G:\HexoBlog,右键进入Git Bash,输入命令。 1npm install -g hexo-cli //出现以下即安装成功 安装 Hexo 完成后，继续依次执行下列命令。 123hexo init blog //这个过程会受网络限制，耐心等待。cd blog npm install 之后执行以下命令，以后必用： 1234hexo clean //清除缓存，这里不执行hexo g //重新生成(执行)hexo s //本地服务浏览（执行）hexo d //推送至Github,这里不执行 至此，可打开浏览器输入：localhost:4000,本地查看博客效果，按ctrl+c停止。 下载主题-Next1.安装 Git 部署插件： 2.下载Next,参考安装包，或直接克隆。 启用主题123在 Hexo 中有2份主要的配置文件，其名称都是_config.yml。 其中，一份位于博客根目录下，主要包含Hexo本身的配置；另一份位于themes/next/目录下，用于配置主题相关的选项。打开themes/next/下的_config.yml,查找scheme，可以看到四种不同的风格。去掉#注释，即启用对应的scheme，博主采用Gemini主题，大家可以依次测试效果，选择自己喜欢的scheme。打开根目录下的_config.yml，查找theme字段，将字段改为theme: next(冒号:之后要有空格分隔，否则无效) 之后通过hexo g和hexo s，再在浏览器中访问localhost:4000即可本地预览主题效果。 主题基础配置设置过程中，可运行在本地查看，步骤跟之前一样(注意所有的：后面都要空一格!!!)。 1.设置菜单打开themes/next/下的_config.yml，查找menu，去掉#注释即可显示对应的菜单项。 2.设置网站基本信息和语言打开根目录下的_config.yml，找到Site如下设置。 3.设置个人信息打开themes/next/下的_config.yml，找到social如下设置。 4.设置头像进入themes/next/source/images下，找到avatar.gif，放入一张同样大小的图片替换名字。之后打开themes/next/下的_config.yml，找到avatar如下设置。 创建github仓库经过以上简单的配置，已经基本有个大概了，可以在本地查看效果，别的优化后面介绍，接下来结合github来搭建，至于github就不多介绍了(全球最大同性交友社区)，哈哈哈…可度娘了解。 1.注册github账号。（略，有需要自行百度。） 2.创建一个新仓库。 3.填写仓库信息。 4.建好仓库之后，在仓库界面选择仓库名称下面一行选项中的”settings”进入到仓库的设置界面中。 5.点击箭头选择一个主题，就可以通过地址在网络上访问了。 6.选择仓库地址，打开根目录下的_config.yml进行设置。 发布到github仓库安装git部署插件npm install hexo-deployer-git --save。 生成SSH秘钥。 创建一个 SSH key 。在命令行（即Git Bash）输入以下命令， 回车三下即可： 1$ ssh-keygen -t rsa -C &quot;邮箱地址&quot; 添加到 github。 复制密钥文件内容（路径形如C:\Users\Administrator\.ssh\id_rsa.pub），粘贴到github上setting下面的SSH即可。 测试是否添加成功。在命令行（即Git Bash）依次输入以下命令，返回“You’ve successfully authenticated”即成功： 12$ ssh -T git@github.com$ yes 推送到GithubPages。在命令行（即Git Bash）依次输入以下命令， 返回INFO Deploy done: git即成功推送： 12$ hexo g$ hexo d 等待1分钟左右，浏览器访问网址： https://&lt;Github账号名称&gt;.github.io 至此，您的Hexo博客已经搭建在GithubPages, 域名为https://&lt;Github账号名称&gt;.github.io 教程至此，便能搭建一个最基础的博客，接下来的优化过程可参考以下大佬的教程。 最全博客搭建+主题优化 hexo高阶教程next主题优化 打造个性超赞博客]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
